{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EzpieCo/PyTorch-Crash-Course/blob/main/01-pytorch-intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01 PyTorch Introduction\n",
        "\n",
        "GitHub repository: https://github.com/EzpieCo/PyTorch-Crash-Course\n",
        "\n",
        "Crash Course: https://ezpie.vercel.app/courses/machine-learning\n",
        "\n",
        "In case of an question: https://github.com/EzpieCo/PyTorch-Crash-Course/discussions"
      ],
      "metadata": {
        "id": "bazV0E2TQ2OF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter: Getting started with PyTorch Code"
      ],
      "metadata": {
        "id": "EVUeevRPWftq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Notebooks are the same as a normal python file\n",
        "\n",
        "print(\"Hello Notebook\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jgT2pazYQGPC",
        "outputId": "89f4a689-2b18-43db-9ea5-d8718106cd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Notebook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing your Runtime and check it\n",
        "\n",
        "To change your Runtime go to `Runtime` -> `change runtime type`\n",
        "\n",
        "Then change your runtime from none to GPU from the Hardware accelerator dropdown\n",
        "\n",
        "**NOTE** _since you would be using a free version of google colab you will have a GPU that won't be to fast, but you can pay for a paid version, for this course the free one will work fine too.\n",
        "._"
      ],
      "metadata": {
        "id": "pVX9VAMcOqy7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "qPdpTsyND3nn",
        "outputId": "3c3160e7-cab3-45e1-b074-ed789c1dc603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun  5 14:37:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@title checking runtime with the nvidia-smi\n",
        "\n",
        "\"\"\"\n",
        "NOTE: This will work only if you have your runtime as GPU\n",
        "Funny output right?\n",
        "\"\"\"\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing PyTorch\n",
        "\n",
        "In google colab all the modules are already installed so we don't need to use `pip` here. Just use the import statement to import pytorch: `import torch`"
      ],
      "metadata": {
        "id": "iQ5B9zC8U4FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Checking if pytorch is imported and what version it is\n",
        "# My current version is 2.0.1, for you it may differ if you're viewing this course from the future(wow you invented a time machine?)\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "lVkXZJ8uU8Zg",
        "outputId": "2a22bce8-cb4e-493f-f1da-c8a135d36c59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter: What and how to make Tensors\n",
        "\n",
        "Assume you have a toy box full of colorful bricks of all shapes and sizes. Each block is allocated a distinct value. You can now build a tower by stacking these bricks together. The tower can have numerous tiers, each of which has a collection of blocks stacked on top of one another.\n",
        "\n",
        "Consider each layer of the tower to be a dimension. Each block within a layer has its own position, which we can refer to as a coordinate. The coordinates pinpoint the exact location of the block within the tower.\n",
        "\n",
        "These block towers are known as tensors in machine learning. Tensors are just fancy words for multidimensional arrays. It's like a mystical container that, like our toy blocks, can hold a multitude of numbers. However, unlike blocks, the numbers in a tensor can represent anything you want, such as image pixel values, temperature readings, or even the possibility of a cat chasing a laser pointer.\n",
        "\n",
        "Assume we have a tensor that represents a colorful image. It might come in three sizes: width, height, and color channels. The width and height indicate the image's dimensions, while the color channels indicate how many colors are utilized to represent each pixel. Consider it a colorful edifice made up of thousands of tiny blocks, each representing a pixel in the image.\n",
        "\n",
        "Links to useful resources:\n",
        "\n",
        "video: https://www.youtube.com/watch?v=f5liqUk0ZTw (recommanded)\n",
        "\n",
        "blog: https://towardsdatascience.com/what-are-tensors-in-machine-learning-5671814646ff"
      ],
      "metadata": {
        "id": "DRnncPRTP_Kx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating tensors\n",
        "\n",
        "There are four type of tensors:\n",
        "1. Scalar\n",
        "2. Vector\n",
        "3. Matrix\n",
        "4. Tensor\n",
        "\n",
        "PyTorch tensors are created using the `torch.tensor` you can read about them at - https://pytorch.org/docs/stable/tensors.html"
      ],
      "metadata": {
        "id": "OXGtGr3fQ-6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scalars\n",
        "\n",
        "Imagine you have a box filled with your favorite chocolate bars (I hate chocolate!). Even if every chocolate bar has a mouthwatering flavor, there is something unusual about them because they each have a different sweetness level. Imagine arranging all of these chocolate bars in a row and giving each one a number to indicate how sweet it is. These figures could be zero, positive, or even negative.\n",
        "\n",
        "A scalar is simply a single number, like one of those sweetness ratings. It doesn't have any direction or fancy dimensions. It's just a humble value that can be used to describe something, like the temperature outside, the age of a dinosaur, or the number of donuts in your belly after a wild breakfast adventure."
      ],
      "metadata": {
        "id": "CZadPmZrYIvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating a scalar\n",
        "\n",
        "scalar = torch.tensor(4)\n",
        "scalar"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nLOA2vURRTFz",
        "outputId": "ca818526-cd2f-40bc-c762-84a46ef2bf3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checking what dimension it is\n",
        "scalar.ndim"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wVAH9m-UV15-",
        "outputId": "f1264b09-f1a7-4ac4-ebf4-30f226a90bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Checking why is the dimension is 0\n",
        "\n",
        "# We need to check what shape is of our scalar.\n",
        "scalar.shape"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LlIJ4SxWWebo",
        "outputId": "3a700a19-410c-4cb8-a5e4-814d5ed38ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectors\n",
        "\n",
        "Consider yourself a treasure hunter examining a huge treasure map. You have a reliable compass that informs you which way is north, south, east, and west to aid with your navigation. Consider each direction as a distinct arrow that has a particular length and is pointing in a single direction.\n",
        "\n",
        "A vector in mathematics resembles one of those arrows exactly. It has both direction and magnitude (length). It works like a magical compass, showing us where to go and how far to travel in a specific direction.\n",
        "\n",
        "However, the fact that vectors may represent a wide range of values and ideas is what makes them so fascinating. A vector, for instance, might depict a race car's speed, an object's force, or a spacecraft's motion across the cosmos.\n",
        "\n",
        "Consider a vector that represents the speed of a race car. The car's speed may be determined by the vector's magnitude, and its direction can be determined by its direction of travel, such as whether it is speeding north or east."
      ],
      "metadata": {
        "id": "wWTwCOZSYT7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating a vector\n",
        "\n",
        "vector = torch.tensor([1, 2, 3])\n",
        "vector"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LiKZNXExYagc",
        "outputId": "458f4004-c629-49b4-ece8-32d84d7f8eed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checking what dimension\n",
        "vector.ndim"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UKudJdIAYhco",
        "outputId": "a4c2d647-d54c-4889-bd78-dcb8e91000d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checking why it's 1\n",
        "vector.shape"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iMVs6IIdYwcD",
        "outputId": "b63bc889-1686-4608-b654-baacc30a3aee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix\n",
        "\n",
        "picture yourself as a professional chef preparing a lavish feast. You have a magical kitchen notebook with pages and columns to keep track of all your recipes. Each page is a representation of a distinct dish, and each column is an ingredient. You should note the amount of each item required for the recipe at the intersection of each page and column.\n",
        "\n",
        "A matrix is analogous to your kitchen notebook in mathematics. It consists of a grid of integers set out in columns and rows. Each number in the matrix is referred to as an element and can stand in for whatever youâ€™d like, including scores, temperatures, or even the quantity of sprinkles on a cupcake!\n"
      ],
      "metadata": {
        "id": "yY9X5LgUbJkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating a matrix\n",
        "\n",
        "matrix = torch.tensor([[1, 2, 3],\n",
        "                      [4, 5, 6],\n",
        "                      [7, 8, 9]])\n",
        "\n",
        "matrix"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yr5pCMntbQey",
        "outputId": "eaa1be91-8aae-4db7-a229-51ed7640187b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title what's the dimension\n",
        "\n",
        "matrix.ndim"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ePEUPCUwbau_",
        "outputId": "8fdf7064-fa23-4bfa-9cab-87cdff759702",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title why 2?\n",
        "\n",
        "matrix.shape"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c81Hsbwubjg1",
        "outputId": "ffca97f0-947e-4cd2-cdda-ef3c4fb988c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensor\n",
        "\n",
        "**_Already explained_**\n",
        "\n",
        "Assume you have a toy box full of colorful bricks of all shapes and sizes. Each block is allocated a distinct value. You can now build a tower by stacking these bricks together. The tower can have numerous tiers, each of which has a collection of blocks stacked on top of one another.\n",
        "\n",
        "Consider each layer of the tower to be a dimension. Each block within a layer has its own position, which we can refer to as a coordinate. The coordinates pinpoint the exact location of the block within the tower.\n",
        "\n",
        "These block towers are known as tensors in machine learning. Tensors are just fancy words for multidimensional arrays. It's like a mystical container that, like our toy blocks, can hold a multitude of numbers. However, unlike blocks, the numbers in a tensor can represent anything you want, such as image pixel values, temperature readings, or even the possibility of a cat chasing a laser pointer.\n",
        "\n",
        "Assume we have a tensor that represents a colorful image. It might come in three sizes: width, height, and color channels. The width and height indicate the image's dimensions, while the color channels indicate how many colors are utilized to represent each pixel. Consider it a colorful edifice made up of thousands of tiny blocks, each representing a pixel in the image."
      ],
      "metadata": {
        "id": "ZgpxK8xpbsxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title creating a tensor\n",
        "\n",
        "tensor = torch.tensor([[[1, 2, 3],\n",
        "                        [4, 5, 6],\n",
        "                        [7, 8, 9]]])\n",
        "\n",
        "tensor"
      ],
      "metadata": {
        "id": "MqXfOGRYhprx",
        "outputId": "20c79f55-7b47-452a-a476-41fecb293e68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title what's the dimension\n",
        "tensor.ndim"
      ],
      "metadata": {
        "id": "sD78euThiFY3",
        "outputId": "721fd8c0-dfcd-4e1d-af60-19333869b1c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title why is it 3?\n",
        "\n",
        "tensor.shape"
      ],
      "metadata": {
        "id": "bq5LnfckiKcn",
        "outputId": "5d3dc138-8caf-4496-e628-46e55df2acd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why is it like this\n",
        "\n",
        "You see the tensor here is having a dimension of 1, 3, 3. Maybe you can explain why is it 3 in the last, cause the `3` arrays have 3 values.\n",
        "\n",
        "And if you guessed it right, yes the 3 arrays themselves are the 3 dimension in the second place, but why 1 in the first? you see we have an extra square bracket in it, that's what is being count as the 1 dimension!\n",
        "\n",
        "You can view the image in the github repository for [better understanding](https://github.com/ezpieco/pytorch-crash-course/images/tensor-dimension.png)"
      ],
      "metadata": {
        "id": "eWiAzIVFiRwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter: Reshape, Squeezing and Unsqueezing\n",
        "\n",
        "What do they mean?\n",
        "\n",
        "* Reshape - Reshapes the input tensor to the defined tensor\n",
        "* Squeezing - removing all the `1` dimensions from the given tensor\n",
        "* Unsqueezing - adding `1` dimension to the given tensor"
      ],
      "metadata": {
        "id": "n6TeTmaLoA-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title creating a tensor for trying out\n",
        "\n",
        "x = torch.arange(1, 10)\n",
        "\n",
        "x, x.shape"
      ],
      "metadata": {
        "id": "2ghyWKroo1E6",
        "outputId": "f53f75ef-9b8a-4274-9fba-02da672dcde2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshape\n",
        "\n",
        "Consider having a big box packed with vibrant blocks. A number is represented by each block. Let's imagine you want to arrange these blocks in creative patterns using a variety of shapes and sizes. Machine learning reshaping is similar to arranging these blocks to create new shapes without altering the numbers that are written on the blocks.\n",
        "\n",
        "These are the main reasons why you should even consider reshaping:\n",
        "\n",
        "1. **Input compatibility:** Let's say you have a machine learning algorithm that takes in images of different fruits and tries to classify them. But the algorithm expects the images to have a specific size, like 64 pixels by 64 pixels. However, your fruit images are of various sizes. Reshaping allows you to resize these images, like stretching or squeezing, so that they all become the same size. This way, you can feed them into the algorithm without any issues.\n",
        "\n",
        "2. **Data manipulation:** Imagine you have a long list of numbers in a single row, like [1, 2, 3, 4, 5, 6]. But you want to analyze the numbers in a table format, with rows and columns. Reshaping helps you transform this list into a table-like structure, like [[1, 2], [3, 4], [5, 6]]. Now you have rows and columns, and you can perform various calculations or operations more easily.\n",
        "\n",
        "3. **Model architecture:** Let's say you're building a model to recognize handwritten digits. To process the images effectively, you need to reshape the input data. Think of the images as jigsaw puzzles. Each puzzle piece represents a pixel, and the final image is made up of all these pieces. Reshaping here involves arranging the puzzle pieces in the right order and making sure they fit together properly. By reshaping the image into a 2D grid, you're allowing the model to analyze and understand the pixel patterns better.\n",
        "\n",
        "4. **Error handling:** Imagine you're using a pre-trained model that expects input images to have three color channels (red, green, and blue). However, the image you want to use has only one color channel (grayscale). Reshaping comes to the rescue! You can reshape the image to add the missing color channel dimension, making it compatible with the model's requirements. It's like putting on a pair of magical glasses that can see colors where there were none before!"
      ],
      "metadata": {
        "id": "sqHjCw6GofX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the tensor(1D) to a 1 X 6 dimension\n",
        "\n",
        "reshaped = x.reshape(1, 6) # Reshape into a 1 X 6 dimension\n",
        "\n",
        "reshaped # Output: error!"
      ],
      "metadata": {
        "id": "7JJaPH-_p5Ns",
        "outputId": "bcfb12e4-7c16-4042-e092-2b5463becda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c4743996fb54>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reshaping the tensor(1D) to a 1 X 6 dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Reshape into a 1 X 6 dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreshaped\u001b[0m \u001b[0;31m# Output: error!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 6]' is invalid for input of size 9"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why we got that error\n",
        "\n",
        "you see our tensor(x) has a shape of 9, cause it's from 1 to 9(index order starting from 0). Now if we see it totally makes sence that we can't convert a 9 value tensor into a 6 value tensor, cause then we will be left with 3 values not in that tensor"
      ],
      "metadata": {
        "id": "1Gk7LtyLqUjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title perfect matches\n",
        "\n",
        "\"\"\"\n",
        "Now that we now why it's happening lets see at numbers that multiple to 9, factors of 9 if we say in maths.\n",
        "so that factors can be 1X9, 3X3 and 9X1.\n",
        "Let's put them in code\n",
        "\"\"\"\n",
        "\n",
        "first_combo = x.reshape(1, 9) # 1 X 9 gives 9\n",
        "print(f'First combo: {first_combo}')\n",
        "\n",
        "second_combo = x.reshape(3, 3) # 3 X 3 gives 9\n",
        "print(f'Second combo: {second_combo}')\n",
        "\n",
        "third_combo = x.reshape(9, 1) # 9 X 1 gives 9\n",
        "print(f'Third combo: {third_combo}')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wYozCjTIq7bU",
        "outputId": "df635c2f-f7de-44fd-8393-d91e96fe9832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First combo: tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
            "Second combo: tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Third combo: tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6],\n",
            "        [7],\n",
            "        [8],\n",
            "        [9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Squeezing\n",
        "\n",
        "Imagine you have a playful bunch of inflatable toys, each representing a tensor. These toys come in different shapes and sizes, but they all have one thing in common: they can expand and contract like balloons. Now, squeezing in machine learning is a bit like manipulating these inflatable toys to make them smaller in certain dimensions, just like squeezing the air out of a balloon!\n",
        "\n",
        "In machine learning, squeezing refers to the process of removing dimensions with a size of 1 from a tensor. It's like compressing or squishing the tensor to make it more compact, without losing any valuable information. Squeezing is particularly useful when dealing with tensors that have unnecessary or redundant dimensions.\n",
        "\n",
        "Here are a few scenarios where squeezing comes into play:\n",
        "\n",
        "1. **Dimension reduction:** Let's say you have a tensor that represents the probabilities of different classes for a classification task. If the tensor has a shape of (1, 10, 1), it means there's only one sample, ten classes, and one prediction per class. In this case, squeezing can be applied to remove the redundant dimensions, resulting in a tensor with shape (10). Now you have a simple 1D tensor representing the probabilities for each class, without unnecessary dimensions.\n",
        "\n",
        "2. **Model output:** Squeezing is often used to simplify the output of a model. For example, in natural language processing tasks, you may have a language model that generates sequences of words. The model may output sequences with shape (1, T, 1), where T is the length of the generated sequence. By squeezing the tensor along the first and third dimensions, you can obtain a more concise representation of the generated sequence with shape (T)."
      ],
      "metadata": {
        "id": "dp5aIiWvvM6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checking the shape of first_combo tensor\n",
        "\n",
        "first_combo.shape"
      ],
      "metadata": {
        "cellView": "form",
        "id": "K1-SQgDGxqml",
        "outputId": "66e2b1f5-3c34-4396-d77f-2ddaea18c77a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title squeezing the dimension\n",
        "\n",
        "first_combo.squeeze(), first_combo.squeeze().shape "
      ],
      "metadata": {
        "cellView": "form",
        "id": "D577i6D9yal-",
        "outputId": "baebd02d-3d36-4afa-be07-16269e93f125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter: PyTorch and Numpy\n",
        "\n",
        "NumPy stands for \"Numerical Python,\" and it's a popular library in the Python programming language. It provides a set of tools and functions that make it easier to work with numerical data in an efficient and convenient way.\n",
        "\n",
        "With NumPy, you can create and manipulate arrays, which are like containers that hold numbers. These arrays can have one dimension (like a vector), two dimensions (like a matrix), or even more dimensions. Arrays in NumPy are particularly useful because they allow you to perform operations on multiple numbers at once, saving you time and effort.\n",
        "\n",
        "For example, let's say you have a dataset containing the heights of a group of people. You can use NumPy to create an array that holds all those heights. Then, you can easily perform operations on that array, like calculating the average height, finding the tallest person, or even doing more complex mathematical computations.\n",
        "\n",
        "And because of this PyTorch has features just to work with numpy arrays\n",
        "\n",
        "* `starting point as numpy array` -> `needed as pytorch tensor` - use `torch.from_numpy(ndarray)`"
      ],
      "metadata": {
        "id": "ETtnhsMYKl-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title convert numpy array into pytorch tensor\n",
        "\n",
        "# import numpy\n",
        "import numpy as np # Most common way of calling numpy\n",
        "\n",
        "# simple numpy array\n",
        "arr = np.arange(1., 10.)\n",
        "tensor = torch.from_numpy(arr) # Danger: when converting numpy array to torch tensor, use type() and set data type to torch.float32\n",
        "\n",
        "arr, tensor"
      ],
      "metadata": {
        "id": "sCUDKWT9L4hh",
        "outputId": "b96c5a62-ed3f-4d11-c6c5-3c586edf7953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title strange problem\n",
        "\n",
        "\"\"\"\n",
        "As you can see the data type of the tensor is float64, but if you check pytorch documentation\n",
        "you will find out that the default and pytorch's favorate type is float32. Now we have a problem\n",
        "cause if the type is different then we might ran into errors. But the first question is why is it float64?\n",
        "\"\"\"\n",
        "\n",
        "# Default numpy data type\n",
        "print(f\"numpy default type: {arr.dtype}\") # it's float64\n",
        "\n",
        "# in order to convert data type use type()\n",
        "# tensor = torch.from_numpy(arr).type(torch.float32)\n",
        "\n",
        "tensor = torch.from_numpy(arr).type(torch.float32)\n",
        "tensor, tensor.dtype"
      ],
      "metadata": {
        "id": "gFs6IKsMM4Mx",
        "outputId": "df56f422-b6e9-4ccf-86dc-467c86e4c404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy default type: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title converting tensor into numpy array\n",
        "\n",
        "tensor = torch.arange(1., 10.)\n",
        "arr = tensor.numpy()\n",
        "\n",
        "tensor, arr"
      ],
      "metadata": {
        "id": "MnQ33_c2PC1x",
        "outputId": "d0de9fe4-5f5d-4850-9664-027c214ee260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
              " array([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter: Why use Device Agnostic and Setting up\n",
        "\n",
        "Device agnostic refers to the capability of a software or system to work seamlessly across different devices or platforms without requiring specific modifications or adaptations for each device.\n",
        "\n",
        "In the context of machine learning, device agnostic refers to algorithms or models that can run efficiently and effectively on various hardware devices, such as CPUs, GPUs, etc. A device-agnostic model is not tightly coupled to a specific hardware device and can adapt to different devices without major changes to its implementation. \n",
        "\n",
        "For this course we will meanly focus on setting up a GPU for our pytorch model.\n",
        "\n",
        "## Why Use GPU\n",
        "\n",
        "The Reason why we are using GPU rather then a CPU is, it can provide significant advantages in terms of speed and computational power."
      ],
      "metadata": {
        "id": "pFwBRhl-9eww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up device agnostic"
      ],
      "metadata": {
        "id": "Sqr07MhdAFXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checking if GPU is available\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "_5S6XGVM-CYK",
        "outputId": "80a4a3a7-2543-4ab7-f613-21838a87ed19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title setting up device agnostic\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "6VRUxKeL_h2v",
        "outputId": "908e1c34-97a8-4ae8-9cf6-cbb748f647f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing code in device agnostic"
      ],
      "metadata": {
        "id": "G7Mdi63-_xxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title making a tensor\n",
        "\n",
        "# This tensor is going to be in cpu by default\n",
        "tensor = torch.arange(1., 10.)\n",
        "\n",
        "tensor, tensor.device # not in GPU"
      ],
      "metadata": {
        "id": "Zirb9Y0QAQII",
        "outputId": "bdca44c3-ab47-4b1d-8e39-774a67b5c22b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title putting tensor in device agnostic\n",
        "\n",
        "tensor = torch.arange(1., 10.).to(device)\n",
        "\n",
        "tensor # In GPU"
      ],
      "metadata": {
        "id": "FY8M4DEWAhgN",
        "outputId": "8077aee8-aa6a-43c3-a826-7fa8d1d3b037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting into error and fixing them\n",
        "\n",
        "We can get into errors where if any one of the tensors are on another device while the other is/are on another, then performing any kind of action with the tensors with different devices can result in errors.\n",
        "\n",
        "In order to fix these errors we need the tensors to be on the same device, GPU or a CPU"
      ],
      "metadata": {
        "id": "GX2FKysBB4RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title tensors on different devices\n",
        "\n",
        "# This one will be on a CPU\n",
        "CPU_tensor = torch.arange(1., 10.)\n",
        "\n",
        "# This one will be on a GPU\n",
        "GPU_tensor = torch.arange(2., 11.).to(device)\n",
        "\n",
        "CPU_tensor, GPU_tensor"
      ],
      "metadata": {
        "id": "OzFArwMmB7df",
        "outputId": "a7677e97-ed1e-4ffe-f5e9-36144ba390be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
              " tensor([ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title performing addition on the tensors\n",
        "\n",
        "ErrorSum = CPU_tensor + GPU_tensor # This will give an error\n",
        "\n",
        "ErrorSum"
      ],
      "metadata": {
        "id": "OM9bg4CYDoGE",
        "outputId": "c4fe612a-4fe9-433e-f89c-8e7177539437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-dcd709ad2cf9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title performing addition on the tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mErrorSum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCPU_tensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGPU_tensor\u001b[0m \u001b[0;31m# This will give an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mErrorSum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title fix for the problem\n",
        "\n",
        "GPU_tensor2 = CPU_tensor.to(device)\n",
        "\n",
        "# Now performing addition will not result in an error\n",
        "\n",
        "sum = GPU_tensor + GPU_tensor2\n",
        "\n",
        "sum # No error!"
      ],
      "metadata": {
        "id": "G6_fnEs7D92N",
        "outputId": "36fbcccc-e5c1-4cfd-98b6-e7c13648f487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3.,  5.,  7.,  9., 11., 13., 15., 17., 19.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}